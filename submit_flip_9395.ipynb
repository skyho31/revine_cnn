{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submit_flip_9395",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1YqqH5QcwbD3VlnpBze5JhgAbLqI_TmH1",
          "timestamp": 1530139969016
        },
        {
          "file_id": "1BGdmajy9eo7sXQeoO2Z1f0hpGOOJnOa0",
          "timestamp": 1529229047481
        },
        {
          "file_id": "https://github.com/skyho31/revine_cnn/blob/master/flip_lenet_vgg4_ver2.ipynb",
          "timestamp": 1529200774417
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "WIP2PzZMp3B5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Infomation\n",
        "\n",
        "\n",
        "1.   random seed - 9\n",
        "2.   last acc - 93.95\n",
        "3.   epoch - 100\n",
        "4.   batch_size - 128\n",
        "\n",
        "\n",
        "conv64(3x3) - bn - relu - maxpool(2x2) - dropout(0.3) -\n",
        "\n",
        "conv64(3x3) - bn - relu - maxppol(2x2) - dropout(0.3) -\n",
        "\n",
        "affine(256) - bn - relu  - dropout(0.3) -\n",
        "\n",
        "affine (64)- bn - relu  - dropout(0.3) -\n",
        "\n",
        "affine(10) - softmax\n",
        "\n",
        "2 ensemble model\n",
        "\n",
        "\n",
        "\n",
        "#####풀잎 3기 / 딥러닝 설레는 첫만남 - 김선호 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "l2eYpbvEpwM4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 0. Instal Cupy\n",
        "\n",
        "colab 환경이 아닐 경우, 아래 코드를 주석 처리 하고 개별 설치 필요"
      ]
    },
    {
      "metadata": {
        "id": "6WvsvtpbL2uf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "9c4bea55-dda8-422f-90a7-7152beb140a3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530140599322,
          "user_tz": -540,
          "elapsed": 12199,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install cupy-cuda80 chainer\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcusparse8.0 is already the newest version (8.0.61-1).\n",
            "libnvrtc8.0 is already the newest version (8.0.61-1).\n",
            "libnvtoolsext1 is already the newest version (8.0.61-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
            "Requirement already satisfied: cupy-cuda80 in /usr/local/lib/python3.6/dist-packages (4.2.0)\n",
            "Requirement already satisfied: chainer in /usr/local/lib/python3.6/dist-packages (4.2.0)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (0.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.14.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer) (3.0.4)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer) (39.1.0)\n",
            "Requirement already satisfied: Augmentor in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (1.14.5)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.23.4)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (0.16.0)\n",
            "Requirement already satisfied: Pillow>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=4.0.0->Augmentor) (0.45.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HefS85hHS0rW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 1 - import module"
      ]
    },
    {
      "metadata": {
        "id": "uXQlGlNFN9Q-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "2eb76015-5f51-4252-c0d2-ca7facce8271",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530140601512,
          "user_tz": -540,
          "elapsed": 2164,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import pickle\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oqMlQKdmS5If",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 2 - define functions"
      ]
    },
    {
      "metadata": {
        "id": "qZ4jjk_8Os3y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "dc256f50-0a6d-4e29-d34f-5a2fa8c93a6a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530140602398,
          "user_tz": -540,
          "elapsed": 749,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# define def\n",
        "def identify_function(x):\n",
        "    return x\n",
        "\n",
        "def step_function(x):\n",
        "    return cp.array(x > 0, dtype=cp.int)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + cp.exp(-x))\n",
        "\n",
        "def sigmoid_grad(x):\n",
        "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
        "\n",
        "def relu(x):\n",
        "    return cp.maximum(0, x)\n",
        "\n",
        "def relu_grad(x):\n",
        "    grad = cp.zeros(x)\n",
        "    grad[x>=0] = 1\n",
        "    return grad\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - cp.max(x, axis=0)\n",
        "        y = cp.exp(x) / cp.sum(cp.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - cp.max(x) # 오버플로 대책\n",
        "    return cp.exp(x) / cp.sum(cp.exp(x))\n",
        "\n",
        "def mean_squared_error(y, t):\n",
        "    return 0.5 * cp.sum((y-t)**2)\n",
        "\n",
        "# def cross_entropy_error(y, t):\n",
        "#     delta = 1e-7\n",
        "#     return -1 * cp.sum(t * cp.log(y + delta))\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "    return -cp.sum(cp.log(y[cp.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "    \n",
        "def softmax_loss(x,t):\n",
        "    y = softmax(x)\n",
        "    return cross_entropy_error(y, t)\n",
        "\n",
        "def im2col(icput_data, filter_h, filter_w, stride=1, pad=0):\n",
        "    \n",
        "    N, C, H, W = icput_data.shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "\n",
        "    img = cp.pad(icput_data, [(0,0), (0,0), (pad, pad), (pad,pad)], 'constant')\n",
        "    col = cp.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        "\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
        "    return col\n",
        "\n",
        "def col2im(col, icput_shape, filter_h, filter_w, stride=1, pad=0):\n",
        "    N, C, H, W = icput_shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride+1\n",
        "    out_w = (W + 2*pad - filter_w)//stride+1\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0,3,4,5,1,2)\n",
        "\n",
        "    img = cp.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride -1))\n",
        "\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] = col[:, :, y, x, :, :]\n",
        "\n",
        "    return img[:, :, pad:H + pad, pad:W + pad]\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4\n",
        "    grad = cp.zeros_like(x)\n",
        "\n",
        "    it = cp.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        fxh1 = f(x)\n",
        "\n",
        "        x[idx] = tmp_val - h\n",
        "        fxh2 = f(x)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "\n",
        "        x[idx] = tmp_val\n",
        "        it.iternext()\n",
        "\n",
        "    return grad"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lRu1pxJWS8V7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 3 - define optimizer\n",
        "adam"
      ]
    },
    {
      "metadata": {
        "id": "1CtgecYGO1_V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "de6e64c3-b9b6-4dfa-f288-9e6411c092fc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530140603028,
          "user_tz": -540,
          "elapsed": 502,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define optimizer\n",
        "class Adam:\n",
        "\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.m is None:\n",
        "            self.m, self.v = {}, {}\n",
        "            for key, val in params.items():\n",
        "                self.m[key] = cp.zeros_like(val)\n",
        "                self.v[key] = cp.zeros_like(val)\n",
        "\n",
        "        self.iter += 1\n",
        "        lr_t = self.lr * cp.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
        "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n",
        "\n",
        "            params[key] -= lr_t * self.m[key] / (cp.sqrt(self.v[key]) + 1e-8)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "an2VvBQLTmsv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# step 4 - define layer\n",
        "relu, convolution, pooling, affine"
      ]
    },
    {
      "metadata": {
        "id": "rESey8s6PCJC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "8006c4e6-3a40-48b1-8bbc-7aba9be0c5ad",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530140605230,
          "user_tz": -540,
          "elapsed": 2102,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define layer\n",
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx\n",
        "      \n",
        "class LeakyRelu:\n",
        "    def __init__(self, alpha=0.3):\n",
        "        self.mask = None\n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = out[self.mask] * self.alpha\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = dout[self.mask] * self.alpha\n",
        "        dx = dout\n",
        "        \n",
        "        return dx\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = sigmoid(x)\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "        return dx\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.original_x_shape = x.shape # 텐서 대책이란?\n",
        "        x = x.reshape(x.shape[0], -1) # reshape에서 -1의 의미는?\n",
        "        self.x = x\n",
        "       \n",
        "        out = cp.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = cp.dot(dout, self.W.T)\n",
        "        self.dW = cp.dot(self.x.T, dout)\n",
        "        self.db = cp.sum(dout, axis=0)\n",
        "\n",
        "        dx = dx.reshape(*self.original_x_shape) #입력 데이터 모양 변경 이유? 텐서 대응 how?\n",
        "        return dx\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None\n",
        "        self.y = None\n",
        "        self.t = None\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size:\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[cp.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "\n",
        "        return dx\n",
        "\n",
        "class Convolution:\n",
        "    def __init__(self, W, b, stride=1, pad=0):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        # for backward\n",
        "        self.x = None\n",
        "        self.col = None\n",
        "        self.col_W = None\n",
        "\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
        "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
        "\n",
        "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
        "        col_W = self.W.reshape(FN, -1).T\n",
        "\n",
        "        out = cp.dot(col, col_W) + self.b\n",
        "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        "        \n",
        "        self.x = x\n",
        "        self.col = col\n",
        "        self.col_W = col_W\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
        "\n",
        "        self.db = cp.sum(dout, axis=0)\n",
        "        self.dW = cp.dot(self.col.T, dout)\n",
        "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
        "\n",
        "        dcol = cp.dot(dout, self.col_W.T)\n",
        "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
        "\n",
        "        return dx\n",
        "\n",
        "class Pooling:\n",
        "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
        "        self.pool_h = pool_h\n",
        "        self.pool_w = pool_w\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        self.x = None\n",
        "        self.arg_max = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
        "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
        "\n",
        "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
        "\n",
        "        arg_max = cp.argmax(col, axis=1)\n",
        "        out = cp.max(col, axis=1)\n",
        "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        "\n",
        "        self.x = x\n",
        "        self.arg_max = arg_max\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout = dout.transpose(0, 2, 3, 1)\n",
        "\n",
        "        pool_size = self.pool_h * self.pool_w\n",
        "        dmax = cp.zeros((dout.size, pool_size))\n",
        "        dmax[cp.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
        "        dmax = dmax.reshape(dout.shape + (pool_size,))\n",
        "\n",
        "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
        "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "\n",
        "        return dx\n",
        "      \n",
        "class Dropout:\n",
        "    \"\"\"\n",
        "    http://arxiv.org/abs/1207.0580\n",
        "    \"\"\"\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            self.mask = cp.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask\n",
        "    \n",
        "class BatchNormalization:\n",
        "    \"\"\"\n",
        "    http://arxiv.org/abs/1502.03167\n",
        "    \"\"\"\n",
        "    def __init__(self, gamma, beta, momentum=0.9, running_mean=None, running_var=None):\n",
        "        self.gamma = gamma\n",
        "        self.beta = beta\n",
        "        self.momentum = momentum\n",
        "        self.icput_shape = None # 합성곱 계층은 4차원, 완전연결 계층은 2차원  \n",
        "\n",
        "        # 시험할 때 사용할 평균과 분산\n",
        "        self.running_mean = running_mean\n",
        "        self.running_var = running_var  \n",
        "        \n",
        "        # backward 시에 사용할 중간 데이터\n",
        "        self.batch_size = None\n",
        "        self.xc = None\n",
        "        self.std = None\n",
        "        self.dgamma = None\n",
        "        self.dbeta = None\n",
        "\n",
        "    def forward(self, x, train_flg=True):\n",
        "        self.icput_shape = x.shape\n",
        "        if x.ndim != 2:\n",
        "            N, C, H, W = x.shape\n",
        "            x = x.reshape(N, -1)\n",
        "\n",
        "        out = self.__forward(x, train_flg)\n",
        "        \n",
        "        return out.reshape(*self.icput_shape)\n",
        "            \n",
        "    def __forward(self, x, train_flg):\n",
        "        if self.running_mean is None:\n",
        "            N, D = x.shape\n",
        "            self.running_mean = cp.zeros(D)\n",
        "            self.running_var = cp.zeros(D)\n",
        "                        \n",
        "        if train_flg:\n",
        "            mu = x.mean(axis=0)\n",
        "            xc = x - mu\n",
        "            var = cp.mean(xc**2, axis=0)\n",
        "            std = cp.sqrt(var + 10e-7)\n",
        "            xn = xc / std\n",
        "            \n",
        "            self.batch_size = x.shape[0]\n",
        "            self.xc = xc\n",
        "            self.xn = xn\n",
        "            self.std = std\n",
        "            self.running_mean = self.momentum * self.running_mean + (1-self.momentum) * mu\n",
        "            self.running_var = self.momentum * self.running_var + (1-self.momentum) * var            \n",
        "        else:\n",
        "            xc = x - self.running_mean\n",
        "            xn = xc / ((cp.sqrt(self.running_var + 10e-7)))\n",
        "        \n",
        "        out = self.gamma * xn + self.beta \n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        if dout.ndim != 2:\n",
        "            N, C, H, W = dout.shape\n",
        "            dout = dout.reshape(N, -1)\n",
        "\n",
        "        dx = self.__backward(dout)\n",
        "\n",
        "        dx = dx.reshape(*self.icput_shape)\n",
        "        return dx\n",
        "\n",
        "    def __backward(self, dout):\n",
        "        dbeta = dout.sum(axis=0)\n",
        "        dgamma = cp.sum(self.xn * dout, axis=0)\n",
        "        dxn = self.gamma * dout\n",
        "        dxc = dxn / self.std\n",
        "        dstd = -cp.sum((dxn * self.xc) / (self.std * self.std), axis=0)\n",
        "        dvar = 0.5 * dstd / self.std\n",
        "        dxc += (2.0 / self.batch_size) * self.xc * dvar\n",
        "        dmu = cp.sum(dxc, axis=0)\n",
        "        dx = dxc - dmu / self.batch_size\n",
        "        \n",
        "        self.dgamma = dgamma\n",
        "        self.dbeta = dbeta\n",
        "        \n",
        "        return dx\n",
        "    \n",
        "# class ResRelu:\n",
        "#     def __init__(self, conv1, conv2, res, beforeRes=None):\n",
        "#         self.conv1 = conv1\n",
        "#         self.conv2 = conv2\n",
        "#         self.res = res\n",
        "#         self.beforeRes = beforRes\n",
        "#         self.layers = []\n",
        "        \n",
        "#     def forward(self):\n",
        "#         conv1."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gg35Xeq_Thpj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 5- define trainer"
      ]
    },
    {
      "metadata": {
        "id": "ovFL_nOlO6Z9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "cd0b0b6e-1ce6-49b1-c8f1-0286c339f914",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530140606040,
          "user_tz": -540,
          "elapsed": 682,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define trainer\n",
        "class Trainer:\n",
        "    \"\"\"신경망 훈련을 대신 해주는 클래스\n",
        "    \"\"\"\n",
        "    def __init__(self, network, x_train, t_train, x_test, t_test,\n",
        "                 epochs=20, mini_batch_size=100,\n",
        "                 optimizer='adam', optimizer_param={'lr':0.01}, \n",
        "                 evaluate_sample_num_per_epoch=None, verbose=True, name=\"PPNet\"):\n",
        "        self.network = network\n",
        "        self.verbose = verbose\n",
        "        self.x_train = x_train\n",
        "        self.t_train = t_train\n",
        "        self.x_test = x_test\n",
        "        self.t_test = t_test\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = mini_batch_size\n",
        "        self.evaluate_sample_num_per_epoch = evaluate_sample_num_per_epoch\n",
        "        self.name = name\n",
        "\n",
        "        # optimzer\n",
        "        optimizer_class_dict = {'adam':Adam}\n",
        "        self.optimizer = optimizer_class_dict[optimizer.lower()](**optimizer_param)\n",
        "        \n",
        "        self.train_size = x_train.shape[0]\n",
        "        self.iter_per_epoch = max(self.train_size // mini_batch_size, 1)\n",
        "        self.max_iter = int(epochs * self.iter_per_epoch)\n",
        "        self.current_iter = 0\n",
        "        self.current_epoch = 0\n",
        "        \n",
        "        self.train_loss_list = []\n",
        "        self.train_acc_list = []\n",
        "        self.test_acc_list = []\n",
        "        \n",
        "        # custom\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def train_step(self, i, max_iter):\n",
        "        start_time_each = time.time()\n",
        "           \n",
        "        batch_mask = cp.random.choice(self.train_size, self.batch_size)\n",
        "        x_batch = self.x_train[batch_mask]\n",
        "        t_batch = self.t_train[batch_mask]\n",
        "        \n",
        "        grads = self.network.gradient(x_batch, t_batch)\n",
        "        self.optimizer.update(self.network.params, grads)\n",
        "        \n",
        "        loss = self.network.loss(x_batch, t_batch)\n",
        "        self.train_loss_list.append(loss)\n",
        "        if self.verbose:\n",
        "            end_time_each = time.time() - start_time_each\n",
        "            infoStr = '=== max_iter:' + str(max_iter) + ' / ' +str(round(i/max_iter*100, 2)) + '%' + '       '  + 'train loss:' + str(loss) +'         time:' + str(int(end_time_each)) + ' seconds' \n",
        "            print(infoStr, end='\\r')\n",
        "          \n",
        "        \n",
        "        if self.current_iter % self.iter_per_epoch == 0:  \n",
        "            self.current_epoch += 1\n",
        "            \n",
        "            x_train_sample, t_train_sample = self.x_train, self.t_train\n",
        "            x_test_sample, t_test_sample = self.x_test, self.t_test\n",
        "            if not self.evaluate_sample_num_per_epoch is None:\n",
        "                t = self.evaluate_sample_num_per_epoch\n",
        "                x_train_sample, t_train_sample = self.x_train[:t], self.t_train[:t]\n",
        "                x_test_sample, t_test_sample = self.x_test[:t], self.t_test[:t]\n",
        "                \n",
        "            train_acc = self.network.accuracy(x_train_sample, t_train_sample)\n",
        "            test_acc = self.network.accuracy(x_test_sample, t_test_sample)\n",
        "            self.train_acc_list.append(train_acc)\n",
        "            self.test_acc_list.append(test_acc)\n",
        "\n",
        "            if self.verbose:\n",
        "                end_time = time.time() - self.start_time\n",
        "                print(\"=== epoch:\" + str(self.current_epoch) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc) + ', train loss:' + str(loss) + \", time :\" + str(int(end_time)) + ' seconds  ===')\n",
        "                self.start_time = time.time()\n",
        "        self.current_iter += 1\n",
        "\n",
        "    def train(self):\n",
        "        for i in range(self.max_iter):\n",
        "            self.train_step(i, self.max_iter)\n",
        "         \n",
        "        test_acc = self.network.accuracy(self.x_test, self.t_test)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"=============== \" + self.name +\" Test Accuracy ===============\")\n",
        "            print(\"test acc:\" + str(test_acc))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rt_8gRBcS_hF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 6 - define PPNet"
      ]
    },
    {
      "metadata": {
        "id": "_8tQbHbwPHfI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "03130b33-1a5f-4561-cdb5-ddad8ea34a03",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530140608128,
          "user_tz": -540,
          "elapsed": 1936,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class PPNet:\n",
        "    \"\"\"\n",
        "      conv - relu - conv - relu - batch - dropout\n",
        "      conv - relu - conv - relu - pooling - dropout\n",
        "      conv - relu - conv - relu - batch - dropout\n",
        "      conv - relu - conv - relu - conv - relu - pooling - \n",
        "      affine - leakyrelu - batch - dropout -\n",
        "      affine - leakyrelu - batch - dropout -\n",
        "      affine - softmax\n",
        "    \"\"\"\n",
        "  \n",
        "  \n",
        "    def __init__(self, input_dim=(1, 28, 28), \n",
        "                 conv_param_1={'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_2={'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_3={'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_4={'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 hidden_size=256, output_size=10, weight_init_std=0.01, weight_decay_lambda = 0):\n",
        "      \n",
        "        # 가중치 초기화\n",
        "        self.weight_decay_lambda = weight_decay_lambda\n",
        "        \n",
        "        conv_output_1 = (input_dim[1] - conv_param_1['filter_size'] + 2*conv_param_1['pad']) / conv_param_1['stride'] + 1\n",
        "        pool_output_1 = conv_output_1 / 2\n",
        "\n",
        "        conv_output_2 = (pool_output_1 - conv_param_2['filter_size'] + 2*conv_param_2['pad']) / conv_param_2['stride'] + 1\n",
        "        pool_output_2 = conv_output_2 / 2\n",
        "        \n",
        " \n",
        "       \n",
        "        \n",
        "\n",
        "        pre_node_nums = [\n",
        "            input_dim[0] * conv_param_1['filter_size'] * conv_param_1['filter_size'],\n",
        "            conv_param_1['filter_num'] * int(pool_output_1) * int(pool_output_1),\n",
        "            conv_param_2['filter_num'] * int(pool_output_2) * int(pool_output_2),\n",
        "            hidden_size,\n",
        "            64,\n",
        "        ]\n",
        "        \n",
        "        print(pre_node_nums)\n",
        "        \n",
        "                \n",
        "        if weight_init_std == 'he':\n",
        "            forHe = np.array(pre_node_nums)\n",
        "            weight_init_scales = np.sqrt(2.0 / forHe) # he 초기값\n",
        "            weight_init_scales = cp.array(weight_init_scales)\n",
        "            #초기 가중치 조절\n",
        "            weight_init_scales[0] /= 10\n",
        "        \n",
        "        else:\n",
        "            length = len(pre_node_nums)\n",
        "            weight_init_scales = cp.full(length, weight_init_std)\n",
        "          \n",
        "                \n",
        "        self.params = {}\n",
        "        pre_channel_num = input_dim[0]\n",
        "        for idx, conv_param in enumerate([conv_param_1, conv_param_2]):\n",
        "          if weight_init_std == 'he':\n",
        "            self.params['W' + str(idx+1)] = weight_init_scales[idx] * cp.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
        "          else:\n",
        "            self.params['W' + str(idx+1)] = weight_init_std * cp.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
        "  \n",
        "          self.params['b' + str(idx+1)] = cp.zeros(conv_param['filter_num'])\n",
        "          pre_channel_num = conv_param['filter_num']\n",
        "        \n",
        "        cnnCount = idx+1\n",
        "        affineCount = cnnCount+1\n",
        "        \n",
        "        self.params['W' + str(affineCount)] = weight_init_scales[affineCount-1] * cp.random.randn(pre_node_nums[affineCount-1], 256)\n",
        "        self.params['b' + str(affineCount)] = cp.zeros(256) \n",
        "        \n",
        "        self.params['W' + str(affineCount+1)] = weight_init_scales[affineCount] * cp.random.randn(256, 64)\n",
        "        self.params['b' + str(affineCount+1)] = cp.zeros(64)    \n",
        "        \n",
        "        self.params['W' + str(affineCount+2)] = weight_init_scales[affineCount+1] * cp.random.randn(64, output_size)\n",
        "        self.params['b' + str(affineCount+2)] = cp.zeros(output_size)\n",
        "        \n",
        "        self.params['gamma1'] = cp.ones(conv_param_1['filter_num'] * int(conv_output_1) * int(conv_output_1))\n",
        "        self.params['beta1'] = cp.zeros(conv_param_1['filter_num'] * int(conv_output_1) * int(conv_output_1))\n",
        "        self.params['gamma2'] = cp.ones(conv_param_2['filter_num'] * int(conv_output_2) * int(conv_output_2))\n",
        "        self.params['beta2'] = cp.zeros(conv_param_2['filter_num'] * int(conv_output_2) * int(conv_output_2))\n",
        "        self.params['gamma3'] = cp.ones(256)\n",
        "        self.params['beta3'] = cp.zeros(256)\n",
        "        self.params['gamma4'] = cp.ones(64)\n",
        "        self.params['beta4'] = cp.zeros(64)\n",
        "\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = []\n",
        "\n",
        "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], conv_param_1['stride'], conv_param_1['pad']))\n",
        "        self.layers.append(BatchNormalization(self.params['gamma1'], self.params['beta1']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
        "        self.layers.append(Dropout(0.3))\n",
        "        \n",
        "        \n",
        "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], conv_param_2['stride'], conv_param_2['pad']))\n",
        "        self.layers.append(BatchNormalization(self.params['gamma2'], self.params['beta2']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
        "        self.layers.append(Dropout(0.3))\n",
        "                 \n",
        "        self.layers.append(Affine(self.params['W' + str(affineCount)], self.params['b' + str(affineCount)])) \n",
        "        self.layers.append(BatchNormalization(self.params['gamma3'], self.params['beta3']))\n",
        "        self.layers.append(Relu()) \n",
        "        self.layers.append(Dropout(0.3))\n",
        "        \n",
        "        self.layers.append(Affine(self.params['W' + str(affineCount+1)], self.params['b' + str(affineCount+1)]))\n",
        "        self.layers.append(BatchNormalization(self.params['gamma4'], self.params['beta4']))\n",
        "        self.layers.append(Relu())\n",
        "        self.layers.append(Dropout(0.3))\n",
        "        \n",
        "        self.layers.append(Affine(self.params['W' + str(affineCount+2)], self.params['b' + str(affineCount+2)])) \n",
        "        self.last_layer = SoftmaxWithLoss() \n",
        "        \n",
        "        self.targetLayer = []\n",
        "        self.targetCount = 0\n",
        "        \n",
        "        for i, layer in enumerate(self.layers):\n",
        "            if isinstance(layer, Convolution) | isinstance(layer, Affine): \n",
        "                self.targetLayer.append(i)\n",
        "                self.targetCount += 1\n",
        "            elif isinstance(layer, BatchNormalization):\n",
        "                self.targetLayer.append(str(i))\n",
        "                self.targetCount += 1\n",
        "\n",
        "    def predict(self, x, train_flg=True):\n",
        "        for layer in self.layers:\n",
        "          if isinstance(layer, Dropout) | isinstance(layer, BatchNormalization):\n",
        "            x = layer.forward(x, train_flg)\n",
        "          else:\n",
        "            x = layer.forward(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t, train_flg=True):\n",
        "        \"\"\"손실 함수를 구한다.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 입력 데이터\n",
        "        t : 정답 레이블\n",
        "        \"\"\"\n",
        "        y = self.predict(x, train_flg)\n",
        "        weight_decay = 0\n",
        "        normalIdx = 0\n",
        "        for idx in self.targetLayer:\n",
        "            if type(idx) == int:\n",
        "              normalIdx += 1\n",
        "              W = self.params['W' + str(normalIdx)]\n",
        "              weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
        "\n",
        "        return self.last_layer.forward(y, t) + weight_decay\n",
        "\n",
        "    def accuracy(self, x, t, batch_size=100):\n",
        "        if t.ndim != 1 : t = cp.argmax(t, axis=1)\n",
        "        \n",
        "        acc = 0.0\n",
        "        \n",
        "        for i in range(int(x.shape[0] / batch_size)):\n",
        "            tx = x[i*batch_size:(i+1)*batch_size]\n",
        "            tt = t[i*batch_size:(i+1)*batch_size]\n",
        "            y = self.predict(tx, train_flg=False)\n",
        "            y = cp.argmax(y, axis=1)\n",
        "            acc += cp.sum(y == tt) \n",
        "        \n",
        "        return acc / x.shape[0]\n",
        "\n",
        "    def numerical_gradient(self, x, t):\n",
        "        \"\"\"기울기를 구한다（수치미분）.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 입력 데이터\n",
        "        t : 정답 레이블\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
        "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
        "            grads['b1']、grads['b2']、... 각 층의 편향\n",
        "        \"\"\"\n",
        "        loss_w = lambda w: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        \n",
        "        normalIdx = 0\n",
        "        batchIdx = 0\n",
        "        for layer_idx in self.targetLayer:\n",
        "            if type(layer_idx) == int:\n",
        "                normalIdx += 1\n",
        "                grads['W' + str(normalIdx)] = numerical_gradient(loss_w, self.params['W' + str(normalIdx)])\n",
        "                grads['b' + str(normalIdx)] = numerical_gradient(loss_w, self.params['b' + str(normalIdx)])\n",
        "            elif type(layer_idx) == str:\n",
        "                batchIdx += 1\n",
        "                grads['gamma' + str(batchIdx)] = numerical_gradient(loss_w, self.params['gamma' + str(batchIdx)])\n",
        "                grads['beta' + str(batchIdx)] = numerical_gradient(loss_w, self.params['beta' + str(batchIdx)])\n",
        "        \n",
        "        return grads\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        \"\"\"기울기를 구한다(오차역전파법).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 입력 데이터\n",
        "        t : 정답 레이블\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
        "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
        "            grads['b1']、grads['b2']、... 각 층의 편향\n",
        "        \"\"\"\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "        \n",
        "        tmp_layers = self.layers.copy()\n",
        "        tmp_layers.reverse()\n",
        "        for layer in tmp_layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 결과 저장\n",
        "        grads = {}\n",
        "        \n",
        "        normalIdx = 0\n",
        "        batchIdx = 0\n",
        "                \n",
        "        for layer_idx in self.targetLayer:\n",
        "            if type(layer_idx) == int:\n",
        "                normalIdx += 1\n",
        "                grads['W' + str(normalIdx)] = self.layers[layer_idx].dW + self.weight_decay_lambda * self.params['W' + str(normalIdx)]\n",
        "                grads['b' + str(normalIdx)] = self.layers[layer_idx].db\n",
        "            elif type(layer_idx) == str:\n",
        "                batchIdx += 1\n",
        "                grads['gamma' + str(batchIdx)] = self.layers[int(layer_idx)].dgamma\n",
        "                grads['beta' + str(batchIdx)] = self.layers[int(layer_idx)].dbeta\n",
        "       \n",
        "            \n",
        "        return grads\n",
        "\n",
        "\n",
        "    def save_params(self, file_name=\"params.pkl\"):\n",
        "        params = {}\n",
        "        for key, val in self.params.items():\n",
        "            params[key] = val\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(params, f)\n",
        "\n",
        "    def load_params(self, file_name=\"params.pkl\"):\n",
        "        with open(file_name, 'rb') as f:\n",
        "            params = pickle.load(f)\n",
        "        for key, val in params.items():\n",
        "            self.params[key] = val\n",
        "      \n",
        "        normalIdx = 0\n",
        "        batchIdx = 0\n",
        "        for layer_idx in enumerate(self.targetLayer):\n",
        "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
        "            self.layers[layer_idx].b = self.params['b' + str(i+1)]\n",
        "            \n",
        "        for layer_idx in self.targetLayer:\n",
        "            if type(layer_idx) == int:\n",
        "                normalIdx += 1\n",
        "                self.layers[layer_idx].W = self.params['W' + str(normalIdx)]\n",
        "                self.layers[layer_idx].b = self.params['b' + str(normalIdx)]\n",
        "            elif type(layer_idx) == str:\n",
        "                batchIdx += 1\n",
        "                self.layers[int(layer_idx)].dgamma = self.params['dgamma' + str(batchIdx)]\n",
        "                self.layers[int(layer_idx)].dbeta = self.params['dbeta' + str(batchIdx)]\n",
        "            "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8T4cJZqXTKsv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 7 - execute code"
      ]
    },
    {
      "metadata": {
        "id": "4lMbW7VjgHsL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3570
        },
        "outputId": "d711995b-16d9-41d8-c94b-24e3581c9cd9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530166549589,
          "user_tz": -540,
          "elapsed": 25939588,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# randomSeed\n",
        "cp.random.seed(9)\n",
        "np.random.seed(9)\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "t_train = Augmentor.Pipeline.categorical_labels(t_train)\n",
        "t_test = Augmentor.Pipeline.categorical_labels(t_test)\n",
        "\n",
        "x_train= np.expand_dims(x_train,axis=1)\n",
        "x_test= np.expand_dims(x_test,axis=1)\n",
        "\n",
        "\n",
        "# 0-1로 정규화\n",
        "x_train = (x_train.astype(cp.float32))/255\n",
        "x_test = (x_test.astype(cp.float32))/255\n",
        "\n",
        "# cp 변환\n",
        "x_train = cp.array(x_train)\n",
        "x_test = cp.array(x_test)\n",
        "t_train = cp.array(t_train)\n",
        "t_test = cp.array(t_test)\n",
        "\n",
        "max_epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "network = PPNet(input_dim=(1, 28, 28), \n",
        "                 conv_param_1={'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_2={'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 hidden_size=256, output_size=10, weight_init_std='he', weight_decay_lambda = 1e-6)              \n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "                  epochs=max_epochs, mini_batch_size=batch_size,\n",
        "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
        "                  evaluate_sample_num_per_epoch=10000, name=\"train1model\")\n",
        "\n",
        "network2 = PPNet(input_dim=(1, 28, 28), \n",
        "                 conv_param_1={'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 conv_param_2={'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
        "                 hidden_size=256, output_size=10, weight_init_std='he', weight_decay_lambda = 1e-6)    \n",
        "\n",
        "trainer2 = Trainer(network2, x_train, t_train, x_test, t_test,\n",
        "                  epochs=max_epochs, mini_batch_size=batch_size,\n",
        "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
        "                  evaluate_sample_num_per_epoch=10000,  name=\"train2model\")\n",
        "\n",
        "\n",
        "# 시간 체크\n",
        "start_time = time.time()\n",
        "trainer.train()\n",
        "trainer2.train()\n",
        "\n",
        "\n",
        "# 체크 종료\n",
        "end_time = time.time() - start_time\n",
        "print(\"PPNet took for % seconds\" % end_time)\n",
        "\n",
        "# 매개변수 보관\n",
        "network.save_params(\"params.pkl\")\n",
        "print(\"Saved Network Parameters!\")\n",
        "\n",
        "# 매개변수 보관\n",
        "network2.save_params(\"params2.pkl\")\n",
        "print(\"Saved Network Parameters!\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 12544, 3136, 256, 64]\n",
            "[9, 12544, 3136, 256, 64]\n",
            "=== epoch:1, train acc:0.145, test acc:0.1413, train loss:2.101812607323096, time :11 seconds  ===\n",
            "=== epoch:2, train acc:0.8986, test acc:0.8873, train loss:0.46810909247308197, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:3, train acc:0.9118, test acc:0.8965, train loss:0.2669435785330751, time :137 seconds  ===\n",
            "=== epoch:4, train acc:0.9215, test acc:0.9049, train loss:0.3049719840951049, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:5, train acc:0.9244, test acc:0.9069, train loss:0.32037658037719596, time :136 seconds  ===\n",
            "=== epoch:6, train acc:0.9317, test acc:0.9124, train loss:0.2658658362057627, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:7, train acc:0.9343, test acc:0.913, train loss:0.240373029543633, time :136 seconds  ===\n",
            "=== epoch:8, train acc:0.9356, test acc:0.9128, train loss:0.3265792990415064, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:9, train acc:0.9373, test acc:0.9154, train loss:0.22980286420015497, time :136 seconds  ===\n",
            "=== epoch:10, train acc:0.9439, test acc:0.9186, train loss:0.14797412629633808, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:11, train acc:0.9459, test acc:0.9191, train loss:0.17093622298119243, time :136 seconds  ===\n",
            "=== epoch:12, train acc:0.9451, test acc:0.9232, train loss:0.2581074006515009, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:13, train acc:0.9484, test acc:0.9217, train loss:0.21306079601833447, time :136 seconds  ===\n",
            "=== epoch:14, train acc:0.9496, test acc:0.9228, train loss:0.1627567422300157, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:15, train acc:0.9535, test acc:0.9227, train loss:0.18104395399763273, time :136 seconds  ===\n",
            "=== epoch:16, train acc:0.9561, test acc:0.9248, train loss:0.2460755937197586, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:17, train acc:0.9563, test acc:0.9259, train loss:0.17300098615204454, time :136 seconds  ===\n",
            "=== epoch:18, train acc:0.9571, test acc:0.9266, train loss:0.23204054756048906, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:19, train acc:0.9582, test acc:0.9266, train loss:0.17793883950848674, time :136 seconds  ===\n",
            "=== epoch:20, train acc:0.9601, test acc:0.926, train loss:0.10675235548607988, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:21, train acc:0.96, test acc:0.9252, train loss:0.1764654008682587, time :136 seconds  ===\n",
            "=== epoch:22, train acc:0.9606, test acc:0.9253, train loss:0.13232634516522232, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:23, train acc:0.9636, test acc:0.9271, train loss:0.18124706386406758, time :137 seconds  ===\n",
            "=== epoch:24, train acc:0.9659, test acc:0.9287, train loss:0.21665762519229723, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:25, train acc:0.964, test acc:0.9248, train loss:0.09854610114716301, time :136 seconds  ===\n",
            "=== epoch:26, train acc:0.9687, test acc:0.9292, train loss:0.2952923205342935, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:27, train acc:0.9702, test acc:0.9307, train loss:0.1254295298023292, time :136 seconds  ===\n",
            "=== epoch:28, train acc:0.9716, test acc:0.9323, train loss:0.12079672894102284, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:29, train acc:0.9699, test acc:0.9273, train loss:0.3404042196334264, time :136 seconds  ===\n",
            "=== epoch:30, train acc:0.9724, test acc:0.9301, train loss:0.08026574903095565, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:31, train acc:0.9713, test acc:0.9305, train loss:0.15305061097108613, time :136 seconds  ===\n",
            "=== epoch:32, train acc:0.9754, test acc:0.931, train loss:0.13506238093170897, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:33, train acc:0.9763, test acc:0.9326, train loss:0.17352743582820485, time :136 seconds  ===\n",
            "=== epoch:34, train acc:0.9751, test acc:0.9318, train loss:0.16089488242227612, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:35, train acc:0.9744, test acc:0.9323, train loss:0.171557252272667, time :136 seconds  ===\n",
            "=== epoch:36, train acc:0.9775, test acc:0.9326, train loss:0.1353937278082169, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:37, train acc:0.9749, test acc:0.9337, train loss:0.12217534749360529, time :136 seconds  ===\n",
            "=== epoch:38, train acc:0.9782, test acc:0.9321, train loss:0.19035749208507052, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:39, train acc:0.9786, test acc:0.9323, train loss:0.13530769636513662, time :136 seconds  ===\n",
            "=== epoch:40, train acc:0.979, test acc:0.9331, train loss:0.10976087412281223, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:41, train acc:0.9804, test acc:0.9319, train loss:0.09282534530181309, time :136 seconds  ===\n",
            "=== epoch:42, train acc:0.9771, test acc:0.9305, train loss:0.11893083998437363, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:43, train acc:0.984, test acc:0.9321, train loss:0.17970768023908204, time :136 seconds  ===\n",
            "=== epoch:44, train acc:0.9827, test acc:0.9348, train loss:0.09966413446766831, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:45, train acc:0.983, test acc:0.9355, train loss:0.14025182654806484, time :136 seconds  ===\n",
            "=== epoch:46, train acc:0.9842, test acc:0.9327, train loss:0.07842770488874053, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:47, train acc:0.9836, test acc:0.9334, train loss:0.13165719683540275, time :136 seconds  ===\n",
            "=== epoch:48, train acc:0.9819, test acc:0.9317, train loss:0.10576348435906834, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:49, train acc:0.9844, test acc:0.9343, train loss:0.08715657996147161, time :136 seconds  ===\n",
            "=== epoch:50, train acc:0.9848, test acc:0.9315, train loss:0.18489687115070633, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:51, train acc:0.9861, test acc:0.9337, train loss:0.17866605234680943, time :136 seconds  ===\n",
            "=== epoch:52, train acc:0.986, test acc:0.9348, train loss:0.060822366623299505, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:53, train acc:0.9845, test acc:0.9321, train loss:0.07030936390616489, time :136 seconds  ===\n",
            "=== epoch:54, train acc:0.9872, test acc:0.9351, train loss:0.1948298090076566, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:55, train acc:0.9863, test acc:0.9317, train loss:0.1433579326704384, time :136 seconds  ===\n",
            "=== epoch:56, train acc:0.9867, test acc:0.9343, train loss:0.1095616183366604, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:57, train acc:0.9867, test acc:0.9322, train loss:0.08441906394096735, time :136 seconds  ===\n",
            "=== epoch:58, train acc:0.9878, test acc:0.9343, train loss:0.1407181844547134, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:59, train acc:0.9879, test acc:0.9346, train loss:0.12958483214516273, time :136 seconds  ===\n",
            "=== epoch:60, train acc:0.9877, test acc:0.9353, train loss:0.07144888859409035, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:61, train acc:0.9897, test acc:0.9338, train loss:0.1827086516437132, time :135 seconds  ===\n",
            "=== epoch:62, train acc:0.9894, test acc:0.9344, train loss:0.08019454445522581, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:63, train acc:0.9883, test acc:0.9346, train loss:0.09050537912427359, time :136 seconds  ===\n",
            "=== epoch:64, train acc:0.9884, test acc:0.9307, train loss:0.14177838332500695, time :135 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:65, train acc:0.9893, test acc:0.9346, train loss:0.07169266383541027, time :136 seconds  ===\n",
            "=== epoch:66, train acc:0.9914, test acc:0.932, train loss:0.0854521384961914, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:67, train acc:0.9923, test acc:0.9344, train loss:0.16086578674925217, time :136 seconds  ===\n",
            "=== epoch:68, train acc:0.9915, test acc:0.9334, train loss:0.06439318256600302, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:69, train acc:0.9916, test acc:0.9333, train loss:0.09673969020013724, time :136 seconds  ===\n",
            "=== epoch:70, train acc:0.9905, test acc:0.9326, train loss:0.1027768552907941, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:71, train acc:0.9911, test acc:0.9332, train loss:0.0888384666291592, time :136 seconds  ===\n",
            "=== epoch:72, train acc:0.989, test acc:0.9283, train loss:0.10159782576737521, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:73, train acc:0.9891, test acc:0.9287, train loss:0.07531802088743153, time :136 seconds  ===\n",
            "=== epoch:74, train acc:0.9907, test acc:0.9345, train loss:0.11037417028100574, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:75, train acc:0.9917, test acc:0.9342, train loss:0.10412652956439514, time :136 seconds  ===\n",
            "=== epoch:76, train acc:0.9924, test acc:0.933, train loss:0.07122456832650881, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:77, train acc:0.9921, test acc:0.9354, train loss:0.07688495914237349, time :136 seconds  ===\n",
            "=== epoch:78, train acc:0.9919, test acc:0.9345, train loss:0.10813693502633956, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:79, train acc:0.9934, test acc:0.9349, train loss:0.0880133098976224, time :136 seconds  ===\n",
            "=== epoch:80, train acc:0.9937, test acc:0.934, train loss:0.1226164349104879, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:81, train acc:0.9931, test acc:0.9341, train loss:0.07020025086190962, time :136 seconds  ===\n",
            "=== epoch:82, train acc:0.9946, test acc:0.9352, train loss:0.11527177835013942, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:83, train acc:0.9948, test acc:0.9356, train loss:0.16361007118167098, time :136 seconds  ===\n",
            "=== epoch:84, train acc:0.9941, test acc:0.9335, train loss:0.07129124047790232, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:85, train acc:0.9943, test acc:0.9339, train loss:0.05637533904111158, time :136 seconds  ===\n",
            "=== epoch:86, train acc:0.9945, test acc:0.9358, train loss:0.06815014557670675, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:87, train acc:0.9944, test acc:0.934, train loss:0.14455251046887388, time :136 seconds  ===\n",
            "=== epoch:88, train acc:0.9937, test acc:0.9337, train loss:0.07602449978962955, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:89, train acc:0.9955, test acc:0.9343, train loss:0.10838821293618751, time :136 seconds  ===\n",
            "=== epoch:90, train acc:0.9946, test acc:0.9312, train loss:0.1389398866910114, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:91, train acc:0.995, test acc:0.9359, train loss:0.1367053115157208, time :136 seconds  ===\n",
            "=== epoch:92, train acc:0.9913, test acc:0.9302, train loss:0.052328237435622905, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:93, train acc:0.9956, test acc:0.9352, train loss:0.05703200557143796, time :136 seconds  ===\n",
            "=== epoch:94, train acc:0.9942, test acc:0.9329, train loss:0.07304270277298375, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:95, train acc:0.9962, test acc:0.9347, train loss:0.08660284429805476, time :136 seconds  ===\n",
            "=== epoch:96, train acc:0.9945, test acc:0.9352, train loss:0.14921441975429206, time :136 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:97, train acc:0.9961, test acc:0.935, train loss:0.1196720499500904, time :136 seconds  ===\n",
            "=== epoch:98, train acc:0.9948, test acc:0.9331, train loss:0.11553005620819513, time :122 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:99, train acc:0.9948, test acc:0.9337, train loss:0.1253434128125255, time :86 seconds  ===\n",
            "=== epoch:100, train acc:0.9961, test acc:0.9339, train loss:0.08142847634564432, time :75 seconds  ===\n",
            "=============== train1model Test Accuracy ===============\n",
            "test acc:0.9346\n",
            "=== epoch:1, train acc:0.267, test acc:0.2697, train loss:2.0686705209323555, time :13503 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:2, train acc:0.8958, test acc:0.8818, train loss:0.3759167547731505, time :132 seconds  ===\n",
            "=== epoch:3, train acc:0.9046, test acc:0.8903, train loss:0.3185505720398976, time :101 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:4, train acc:0.8998, test acc:0.8823, train loss:0.4377479486049468, time :132 seconds  ===\n",
            "=== epoch:5, train acc:0.9229, test acc:0.9028, train loss:0.27153683621519675, time :133 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:6, train acc:0.9253, test acc:0.9099, train loss:0.354754801249604, time :133 seconds  ===\n",
            "=== epoch:7, train acc:0.9319, test acc:0.9129, train loss:0.35669186481550036, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:8, train acc:0.9362, test acc:0.9111, train loss:0.23554551644789512, time :132 seconds  ===\n",
            "=== epoch:9, train acc:0.939, test acc:0.9159, train loss:0.2839290183964219, time :133 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:10, train acc:0.9426, test acc:0.9189, train loss:0.20005438678696408, time :131 seconds  ===\n",
            "=== epoch:11, train acc:0.9484, test acc:0.9223, train loss:0.1931663874080469, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:12, train acc:0.9449, test acc:0.9207, train loss:0.20149744095287897, time :132 seconds  ===\n",
            "=== epoch:13, train acc:0.9506, test acc:0.9241, train loss:0.17451280310503284, time :133 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:14, train acc:0.9473, test acc:0.9187, train loss:0.18370378836856258, time :132 seconds  ===\n",
            "=== epoch:15, train acc:0.9537, test acc:0.9262, train loss:0.16278078201118446, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:16, train acc:0.956, test acc:0.9289, train loss:0.17302528337586895, time :132 seconds  ===\n",
            "=== epoch:17, train acc:0.9579, test acc:0.9274, train loss:0.2018577185932312, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:18, train acc:0.9543, test acc:0.9239, train loss:0.12126311057748888, time :132 seconds  ===\n",
            "=== epoch:19, train acc:0.9589, test acc:0.9297, train loss:0.18483834984029177, time :131 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:20, train acc:0.9592, test acc:0.9269, train loss:0.19547796076875276, time :131 seconds  ===\n",
            "=== epoch:21, train acc:0.9603, test acc:0.9243, train loss:0.1492879974596293, time :131 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:22, train acc:0.9621, test acc:0.9291, train loss:0.11632535260104551, time :132 seconds  ===\n",
            "=== epoch:23, train acc:0.9631, test acc:0.9294, train loss:0.1463567319134736, time :131 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:24, train acc:0.9666, test acc:0.9307, train loss:0.15468582672428022, time :131 seconds  ===\n",
            "=== epoch:25, train acc:0.9632, test acc:0.9265, train loss:0.1863517311584259, time :131 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:26, train acc:0.9677, test acc:0.929, train loss:0.16414389222352965, time :131 seconds  ===\n",
            "=== epoch:27, train acc:0.9713, test acc:0.9322, train loss:0.1905440486080636, time :131 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:28, train acc:0.9723, test acc:0.9308, train loss:0.18486438342500458, time :131 seconds  ===\n",
            "=== epoch:29, train acc:0.9735, test acc:0.9327, train loss:0.17414279208375857, time :129 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:30, train acc:0.9729, test acc:0.9318, train loss:0.22606677964532462, time :130 seconds  ===\n",
            "=== epoch:31, train acc:0.9744, test acc:0.9301, train loss:0.19211434306457212, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:32, train acc:0.9753, test acc:0.9323, train loss:0.1578993307378688, time :131 seconds  ===\n",
            "=== epoch:33, train acc:0.9676, test acc:0.9254, train loss:0.12326684790480674, time :133 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:34, train acc:0.9765, test acc:0.934, train loss:0.15100553908924094, time :132 seconds  ===\n",
            "=== epoch:35, train acc:0.977, test acc:0.9331, train loss:0.26073550928161987, time :133 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:36, train acc:0.9767, test acc:0.9345, train loss:0.218914734160535, time :132 seconds  ===\n",
            "=== epoch:37, train acc:0.9781, test acc:0.931, train loss:0.11771761395068307, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:38, train acc:0.9791, test acc:0.9342, train loss:0.14010165268041458, time :132 seconds  ===\n",
            "=== epoch:39, train acc:0.977, test acc:0.9328, train loss:0.14152839600577186, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:40, train acc:0.9797, test acc:0.9345, train loss:0.14759070126787685, time :132 seconds  ===\n",
            "=== epoch:41, train acc:0.9822, test acc:0.9321, train loss:0.09541441878546832, time :131 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:42, train acc:0.9813, test acc:0.932, train loss:0.25542349107063145, time :132 seconds  ===\n",
            "=== epoch:43, train acc:0.9804, test acc:0.9338, train loss:0.15428038442378916, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:44, train acc:0.9846, test acc:0.9346, train loss:0.10390103923315169, time :133 seconds  ===\n",
            "=== epoch:45, train acc:0.9822, test acc:0.9322, train loss:0.17315175165023608, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:46, train acc:0.9812, test acc:0.9332, train loss:0.059263678727809396, time :132 seconds  ===\n",
            "=== epoch:47, train acc:0.9819, test acc:0.9338, train loss:0.15290043131262854, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:48, train acc:0.9808, test acc:0.9307, train loss:0.16824434155602247, time :132 seconds  ===\n",
            "=== epoch:49, train acc:0.9829, test acc:0.9357, train loss:0.1454923425450509, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:50, train acc:0.9839, test acc:0.9303, train loss:0.10208323546328457, time :132 seconds  ===\n",
            "=== epoch:51, train acc:0.9862, test acc:0.934, train loss:0.12081193632678841, time :133 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:52, train acc:0.9851, test acc:0.9358, train loss:0.08897969503899614, time :131 seconds  ===\n",
            "=== epoch:53, train acc:0.9871, test acc:0.9342, train loss:0.08155012849232905, time :131 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:54, train acc:0.9864, test acc:0.935, train loss:0.09502917385631741, time :132 seconds  ===\n",
            "=== epoch:55, train acc:0.9879, test acc:0.9322, train loss:0.14221574073917712, time :132 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:56, train acc:0.9858, test acc:0.9311, train loss:0.11445934236776707, time :132 seconds  ===\n",
            "=== epoch:57, train acc:0.9881, test acc:0.9343, train loss:0.13605702211979068, time :133 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:58, train acc:0.9876, test acc:0.9339, train loss:0.09186837727777356, time :131 seconds  ===\n",
            "=== epoch:59, train acc:0.9876, test acc:0.935, train loss:0.1451476919268023, time :131 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:60, train acc:0.9875, test acc:0.9302, train loss:0.11342809304123674, time :78 seconds  ===\n",
            "=== epoch:61, train acc:0.9877, test acc:0.9325, train loss:0.05118341345531313, time :75 seconds  ===\n",
            "=== epoch:62, train acc:0.9877, test acc:0.9343, train loss:0.09952206330835144, time :75 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:63, train acc:0.9864, test acc:0.9336, train loss:0.09781070487937502, time :75 seconds  ===\n",
            "=== epoch:64, train acc:0.9802, test acc:0.9261, train loss:0.1259413285625892, time :75 seconds  ===\n",
            "=== epoch:65, train acc:0.989, test acc:0.9354, train loss:0.12167202500558272, time :76 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:66, train acc:0.9895, test acc:0.9347, train loss:0.12074657470860257, time :77 seconds  ===\n",
            "=== epoch:67, train acc:0.9898, test acc:0.9367, train loss:0.09111534223786943, time :77 seconds  ===\n",
            "=== epoch:68, train acc:0.9923, test acc:0.9358, train loss:0.08872038328578458, time :75 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:69, train acc:0.9913, test acc:0.9339, train loss:0.08271233014649874, time :75 seconds  ===\n",
            "=== epoch:70, train acc:0.9884, test acc:0.9356, train loss:0.12079982070859417, time :77 seconds  ===\n",
            "=== epoch:71, train acc:0.9914, test acc:0.9342, train loss:0.054703007152681525, time :75 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:72, train acc:0.991, test acc:0.9352, train loss:0.06088928851325872, time :75 seconds  ===\n",
            "=== epoch:73, train acc:0.992, test acc:0.9351, train loss:0.17387523263834057, time :77 seconds  ===\n",
            "=== epoch:74, train acc:0.9876, test acc:0.9293, train loss:0.058731361924850525, time :77 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:75, train acc:0.9917, test acc:0.9324, train loss:0.12204909331515564, time :77 seconds  ===\n",
            "=== epoch:76, train acc:0.9921, test acc:0.9358, train loss:0.11160066606654237, time :105 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:77, train acc:0.9922, test acc:0.9319, train loss:0.06375093259356918, time :139 seconds  ===\n",
            "=== epoch:78, train acc:0.9928, test acc:0.9351, train loss:0.13437473574775974, time :138 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:79, train acc:0.9924, test acc:0.9319, train loss:0.08904463138210152, time :137 seconds  ===\n",
            "=== epoch:80, train acc:0.9943, test acc:0.9376, train loss:0.06922478736148831, time :138 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:81, train acc:0.993, test acc:0.9363, train loss:0.04518628174169448, time :138 seconds  ===\n",
            "=== epoch:82, train acc:0.9931, test acc:0.9351, train loss:0.07095168461665664, time :137 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:83, train acc:0.9939, test acc:0.9354, train loss:0.1855770402388234, time :139 seconds  ===\n",
            "=== epoch:84, train acc:0.9914, test acc:0.9322, train loss:0.14634395783758913, time :138 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:85, train acc:0.9934, test acc:0.9327, train loss:0.1368735692047922, time :138 seconds  ===\n",
            "=== epoch:86, train acc:0.9932, test acc:0.934, train loss:0.2008283221181699, time :138 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:87, train acc:0.9934, test acc:0.9316, train loss:0.061534889501070555, time :137 seconds  ===\n",
            "=== epoch:88, train acc:0.9952, test acc:0.9352, train loss:0.1605181453698463, time :138 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:89, train acc:0.9948, test acc:0.9363, train loss:0.2039580636048266, time :139 seconds  ===\n",
            "=== epoch:90, train acc:0.9949, test acc:0.9339, train loss:0.17607622574669743, time :138 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:91, train acc:0.9952, test acc:0.9356, train loss:0.09025830020244148, time :137 seconds  ===\n",
            "=== epoch:92, train acc:0.9943, test acc:0.9364, train loss:0.10533554305239298, time :139 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:93, train acc:0.9955, test acc:0.9351, train loss:0.06908928085644592, time :138 seconds  ===\n",
            "=== epoch:94, train acc:0.9946, test acc:0.9321, train loss:0.07758254763666336, time :138 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:95, train acc:0.9937, test acc:0.9327, train loss:0.06921183190960829, time :139 seconds  ===\n",
            "=== epoch:96, train acc:0.9961, test acc:0.9324, train loss:0.12368773130950113, time :139 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:97, train acc:0.9956, test acc:0.9357, train loss:0.0986066673044466, time :139 seconds  ===\n",
            "=== epoch:98, train acc:0.9959, test acc:0.9346, train loss:0.11968140066225766, time :140 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=== epoch:99, train acc:0.9968, test acc:0.9355, train loss:0.101574438972149, time :138 seconds  ===\n",
            "=== epoch:100, train acc:0.9941, test acc:0.9339, train loss:0.1012879760402254, time :138 seconds  ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "=============== train2model Test Accuracy ===============\n",
            "test acc:0.9358\n",
            "PPNet took for 25936.946343898773econds\n",
            "Saved Network Parameters!\n",
            "Saved Network Parameters!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t4Y_3yjWTIDn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "6256f142-dec2-4687-c663-000ae32f9bd9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530166554019,
          "user_tz": -540,
          "elapsed": 4396,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def ensemble(t1, t2, x, t, batch_size=100):\n",
        "    if t.ndim != 1 : t = cp.argmax(t, axis=1)\n",
        "\n",
        "    acc = 0.0\n",
        "    \n",
        "    for i in range(int(x.shape[0] / batch_size)):\n",
        "        tx = x[i*batch_size:(i+1)*batch_size]\n",
        "        tt = t[i*batch_size:(i+1)*batch_size]\n",
        "        y1 = t1.network.predict(tx, train_flg=False)\n",
        "        y2 = t2.network.predict(tx, train_flg=False)\n",
        "\n",
        "        y = (y1 + y2) / 2\n",
        "        y = cp.argmax(y, axis=1)\n",
        "        acc += cp.sum(y == tt)\n",
        "        \n",
        "    print(\"=============== Final Test Accuracy ===============\")\n",
        "    print(\"final acc:\" + str(acc/x.shape[0]))\n",
        "    \n",
        "    return acc / x.shape[0] "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJ7kWjFYQ84o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "outputId": "57a1edcc-5a8b-4a3e-b0fe-e311b8143af0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530166566811,
          "user_tz": -540,
          "elapsed": 12666,
          "user": {
            "displayName": "Kim Revine",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "105397506758897638550"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "final = ensemble(trainer, trainer2, x_test, t_test)\n",
        "\n",
        "# 그래프 그리기\n",
        "\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(max_epochs)\n",
        "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
        "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0.8000, 1.0000)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x, trainer2.train_acc_list, marker='o', label='train', markevery=2)\n",
        "plt.plot(x, trainer2.test_acc_list, marker='s', label='test', markevery=2)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0.8000, 1.0000)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=============== Final Test Accuracy ===============\n",
            "final acc:0.9395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFcCAYAAADPkheEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f007a3f0438>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFcCAYAAADPkheEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7nPcmFTBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0062525748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}